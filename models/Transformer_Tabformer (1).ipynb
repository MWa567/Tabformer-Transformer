{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5f0-5iKZYgj",
        "outputId": "8d068818-a831-49c8-9475-4bb2501aae46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "!pip install optuna\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Freshman/UROP/Transformer')\n",
        "\n",
        "import data_preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgpwrjQ-ZobK",
        "outputId": "6651b3b3-75e3-429b-b38d-b67b6061c92d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(259335, 24)\n",
            "(1037340, 24)\n"
          ]
        }
      ],
      "source": [
        "data_raw = pd.read_csv('/content/drive/MyDrive/Freshman/UROP/fraud_detection-main/credit_card_transactions.csv')\n",
        "\n",
        "train_data_raw = data_raw.sample(frac=0.2, random_state=42)\n",
        "test_data_raw = data_raw.drop(train_data_raw.index)\n",
        "\n",
        "print(train_data_raw.shape)\n",
        "print(test_data_raw.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jyBOHTobJ1i"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8StpBhDbL7P"
      },
      "outputs": [],
      "source": [
        "from data_preprocessing import data_preprocessing\n",
        "\n",
        "train_data_processed, test_data_processed = data_preprocessing(train_data_raw.sort_values(by = [\"cc_num\"])[:2500], test_data_raw.sort_values(by = [\"cc_num\"])[:20000])\n",
        "\n",
        "train_data_processed = train_data_processed[train_data_processed['is_fraud'] == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMEPRMAiuOEp"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "train_data = train_data_processed.drop(['lat', 'long', 'city_pop', 'state', 'gender', 'Year'], axis=1)\n",
        "test_data = test_data_processed.drop(['lat', 'long', 'city_pop', 'state', 'gender', 'Year'], axis=1)\n",
        "\n",
        "for feature in ['amt', 'merch_lat', 'merch_long', 'LatLong_Dist']:\n",
        "  train_data[feature] = StandardScaler().fit_transform(train_data[feature].values.reshape(-1, 1))\n",
        "  test_data[feature] = StandardScaler().fit_transform(test_data[feature].values.reshape(-1, 1))\n",
        "\n",
        "for feature in ['category', 'Hour', 'Minute', 'Second', 'dayOfWeek']:\n",
        "  train_data[feature] += 1\n",
        "  test_data[feature] += 1\n",
        "\n",
        "column_order = ['cc_num', 'is_fraud', 'category', 'Month', 'Day', 'Hour', 'Minute', 'Second', 'dayOfWeek', 'amt', 'merch_lat', 'merch_long', 'LatLong_Dist']\n",
        "train_data = train_data[column_order]\n",
        "test_data = test_data[column_order]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-LZkZhbB9WCe",
        "outputId": "476bd232-3c4e-458f-be04-e62e8d9b4d3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            cc_num  is_fraud  category  Month  Day  Hour  Minute  Second  \\\n",
              "1017   60416207185         0         1      1    1    13      48      16   \n",
              "2907   60416207185         0         2      1    2    14      11      47   \n",
              "7473   60416207185         0         3      1    5    22      35      21   \n",
              "10739  60416207185         0         4      1    7    13      59      20   \n",
              "14749  60416207185         0         5      1    9    10       2      11   \n",
              "\n",
              "       dayOfWeek       amt  merch_lat  merch_long  LatLong_Dist  \n",
              "1017           2 -0.404749   1.599109   -1.053304      1.750297  \n",
              "2907           3 -0.255188   1.439331   -0.940773     -0.106327  \n",
              "7473           6 -0.421951   1.392894   -0.996827     -2.192852  \n",
              "10739          1  1.074185   1.125739   -0.963345      1.280002  \n",
              "14749          3  0.114020   1.538082   -1.004556      0.122997  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6577fbf7-4f90-413a-bfaa-840947378b83\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cc_num</th>\n",
              "      <th>is_fraud</th>\n",
              "      <th>category</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Minute</th>\n",
              "      <th>Second</th>\n",
              "      <th>dayOfWeek</th>\n",
              "      <th>amt</th>\n",
              "      <th>merch_lat</th>\n",
              "      <th>merch_long</th>\n",
              "      <th>LatLong_Dist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1017</th>\n",
              "      <td>60416207185</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>48</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.404749</td>\n",
              "      <td>1.599109</td>\n",
              "      <td>-1.053304</td>\n",
              "      <td>1.750297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2907</th>\n",
              "      <td>60416207185</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>11</td>\n",
              "      <td>47</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.255188</td>\n",
              "      <td>1.439331</td>\n",
              "      <td>-0.940773</td>\n",
              "      <td>-0.106327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7473</th>\n",
              "      <td>60416207185</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>22</td>\n",
              "      <td>35</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>-0.421951</td>\n",
              "      <td>1.392894</td>\n",
              "      <td>-0.996827</td>\n",
              "      <td>-2.192852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10739</th>\n",
              "      <td>60416207185</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>59</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>1.074185</td>\n",
              "      <td>1.125739</td>\n",
              "      <td>-0.963345</td>\n",
              "      <td>1.280002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14749</th>\n",
              "      <td>60416207185</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>0.114020</td>\n",
              "      <td>1.538082</td>\n",
              "      <td>-1.004556</td>\n",
              "      <td>0.122997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6577fbf7-4f90-413a-bfaa-840947378b83')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6577fbf7-4f90-413a-bfaa-840947378b83 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6577fbf7-4f90-413a-bfaa-840947378b83');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3fb815dd-d7ef-47b7-8c60-b37ac6374532\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3fb815dd-d7ef-47b7-8c60-b37ac6374532')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3fb815dd-d7ef-47b7-8c60-b37ac6374532 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 2459,\n  \"fields\": [\n    {\n      \"column\": \"cc_num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 220727812641,\n        \"min\": 60416207185,\n        \"max\": 502012776709,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          501899453424,\n          501831082224,\n          60416207185\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_fraud\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 14,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Month\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Day\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 31,\n        \"samples\": [\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hour\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Minute\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Second\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dayOfWeek\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 7,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"amt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0002033967274164,\n        \"min\": -0.45147232831954814,\n        \"max\": 40.00450011835768,\n        \"num_unique_values\": 2124,\n        \"samples\": [\n          -0.42848606570041936\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"merch_lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0002033967274155,\n        \"min\": -1.7067222078505904,\n        \"max\": 1.6041925886135806,\n        \"num_unique_values\": 2458,\n        \"samples\": [\n          0.7416543170292599\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"merch_long\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0002033967274149,\n        \"min\": -2.020552286916408,\n        \"max\": 1.3686591441646037,\n        \"num_unique_values\": 2459,\n        \"samples\": [\n          -0.3431455748623135\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LatLong_Dist\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.000203396727415,\n        \"min\": -2.6542974624171745,\n        \"max\": 2.321437917234763,\n        \"num_unique_values\": 2459,\n        \"samples\": [\n          -1.4422446761521515\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qQXE3vnbRPB"
      },
      "source": [
        "Transformer Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXPSo_E9jFUl",
        "outputId": "574b7acc-6f63-4796-8b63-680ced85d09f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWiGu_3KV1hp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import math\n",
        "import copy\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    # the model dimension d_model must be divisible by num_heads\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.num_heads = num_heads\n",
        "    self.d_k = d_model // num_heads # (d_model * num_features // num_heads)\n",
        "\n",
        "    self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
        "    self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
        "    self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
        "    self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
        "\n",
        "  def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "    # Calculate attention scores\n",
        "    attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k) # (batch_size, num_heads, seq_length, seq_length)\n",
        "    if mask is not None:\n",
        "      attn_scores = attn_scores.masked_fill(mask == 0, -1e9) # (batch_size, num_heads, seq_length, seq_length)\n",
        "    attn_probs = torch.softmax(attn_scores, dim=-1) # (batch_size, num_heads, seq_length, seq_length)\n",
        "    output = torch.matmul(attn_probs, V) # (batch_size, num_heads, seq_length, d_k)\n",
        "    return output\n",
        "\n",
        "  def split_heads(self, x):\n",
        "    # Reshape the input to have num_heads for multi-head attention\n",
        "    batch_size, seq_length, d_model = x.size()\n",
        "    return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "  def combine_heads(self, x):\n",
        "    # Combine the multiple heads back to original shape\n",
        "    batch_size, _, seq_length, d_k = x.size()\n",
        "    return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
        "\n",
        "  def forward(self, Q, K, V, mask=None):\n",
        "    Q = self.split_heads(self.W_q(Q)) # (batch_size, num_heads, seq_length, d_k)\n",
        "    K = self.split_heads(self.W_k(K))\n",
        "    V = self.split_heads(self.W_v(V))\n",
        "\n",
        "    attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "\n",
        "    output = self.W_o(self.combine_heads(attn_output)) # (batch_size, seq_length, d_model*num_features)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seDFmoksRnQR"
      },
      "outputs": [],
      "source": [
        "class PositionWiseFeedForward(nn.Module):\n",
        "  def __init__(self, d_model, d_ff):\n",
        "    super(PositionWiseFeedForward, self).__init__()\n",
        "    self.fc1 = nn.Linear(d_model, d_ff)\n",
        "    self.fc2 = nn.Linear(d_ff, d_model)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.fc2(self.relu(self.fc1(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPV-IU-GSsQK"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "  def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "    self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "    self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "    self.norm1 = nn.LayerNorm(d_model)\n",
        "    self.norm2 = nn.LayerNorm(d_model)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x, tgt_mask):\n",
        "    attn_output = self.self_attn(x, x, x, tgt_mask)\n",
        "    x = self.norm1(x + self.dropout(attn_output))\n",
        "    ff_output = self.feed_forward(x)\n",
        "    x = self.norm2(x + self.dropout(attn_output))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAUfi36aiGp7"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, categorical, numeric, num_layers, max_sequence_length, d_model=64, field_depth=1, num_heads=4, dim_feedforward=128, dropout=0.1):\n",
        "    # d_model is the dimensionality of the input\n",
        "    # categorical is the tuple of sizes of each categorical field\n",
        "    # numeric is the number of numeric fields\n",
        "    super(Transformer, self).__init__()\n",
        "    self.categorical = categorical\n",
        "    self.numeric = numeric\n",
        "\n",
        "    self.num_categories = len(categorical)\n",
        "    self.num_numeric = numeric\n",
        "    self.total_fields = self.num_categories + self.num_numeric\n",
        "\n",
        "    self.categorical_embedding = nn.ModuleList([nn.Embedding(c, d_model, padding_idx=0) for c in categorical])\n",
        "    self.numeric_embedding = nn.ModuleList([nn.Linear(1, d_model) for _ in range(numeric)])\n",
        "    self.positional_embedding = nn.Embedding(max_sequence_length, d_model * self.total_fields) # learned positional embedding\n",
        "\n",
        "    self.decoder_layers = nn.ModuleList([DecoderLayer(d_model*self.total_fields, num_heads, dim_feedforward, dropout) for _ in range(num_layers)])\n",
        "\n",
        "    self.cat_output_heads = nn.ModuleList([nn.Linear(d_model*self.total_fields, c) for c in categorical])\n",
        "    self.num_output_heads = nn.ModuleList([nn.Linear(d_model*self.total_fields, 1) for _ in range(numeric)])\n",
        "    self.embed_pred = nn.Linear(d_model * self.total_fields, d_model * self.total_fields)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def generate_mask(self, tgt):\n",
        "    # returning nopeak mask instead of src, tgt, commented out unsqueeze\n",
        "    tgt_mask = (tgt[:, 1] != 0).unsqueeze(0).unsqueeze(1).unsqueeze(3)\n",
        "    seq_length = tgt.size(0)\n",
        "    nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
        "    return nopeak_mask\n",
        "\n",
        "  def forward(self, tgt):\n",
        "    # categorical: Tensor of category indices\n",
        "    # numeric: tensor of numeric values\n",
        "    # return predicted embedding of next transaction for each categorical field\n",
        "\n",
        "    tgt_mask = self.generate_mask(tgt)\n",
        "\n",
        "    tgt_categorical = tgt[:, :self.num_categories].long()\n",
        "    tgt_numeric = tgt[:, self.num_categories:self.num_categories + self.num_numeric + 1].float()\n",
        "\n",
        "    tgt_categorical_embedded = torch.cat([self.categorical_embedding[i](tgt_categorical[:, i]) for i in range(self.num_categories)], dim=1) # (seq_length, num_categories*d_model)\n",
        "    tgt_numeric_embedded = torch.cat([self.numeric_embedding[i](tgt_numeric[:, i].unsqueeze(-1)) for i in range(self.num_numeric)], dim=1) # (seq_length, num_numeric*d_model)\n",
        "\n",
        "    seq_len = tgt.size(0)\n",
        "\n",
        "    position_ids = torch.arange(seq_len, device=tgt.device).unsqueeze(0)  # shape (1, seq_len)\n",
        "    pos_embedding = self.positional_embedding(position_ids)               # shape (1, seq_len, d_model * total_fields)\n",
        "\n",
        "    tgt_embedded = self.dropout(torch.cat([tgt_categorical_embedded, tgt_numeric_embedded], dim=1).unsqueeze(0) + pos_embedding)\n",
        "\n",
        "    dec_output = tgt_embedded # (batch_size, seq_length, num_features * d_model)\n",
        "    for dec_layer in self.decoder_layers:\n",
        "      dec_output = dec_layer(dec_output, tgt_mask)\n",
        "\n",
        "    # Use last transaction's output to predict the next one\n",
        "    last_output = dec_output # (batch_size, seq_length, num_features * d_model)\n",
        "    pred_next_emb = self.embed_pred(last_output) # (batch_size, seq_length, num_features * d_model)\n",
        "\n",
        "    cat_preds = [head(last_output) for head in self.cat_output_heads]       # logits for each categorical field\n",
        "    num_preds = [head(last_output) for head in self.num_output_heads]  # numeric values\n",
        "    return pred_next_emb, cat_preds, num_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5upqcHW_trH"
      },
      "outputs": [],
      "source": [
        "# Get training and testing data\n",
        "\n",
        "# Pad end with 0's\n",
        "train_num_trans_per_user = []\n",
        "for user in train_data['cc_num'].unique():\n",
        "  train_num_trans_per_user.append(train_data[train_data['cc_num'] == user].shape[0])\n",
        "\n",
        "train_max_len = max(train_num_trans_per_user)\n",
        "\n",
        "test_num_trans_per_user = []\n",
        "for user in test_data['cc_num'].unique():\n",
        "  test_num_trans_per_user.append(test_data[test_data['cc_num'] == user].shape[0])\n",
        "\n",
        "test_max_len = max(test_num_trans_per_user)\n",
        "\n",
        "max_len = max(train_max_len, test_max_len)\n",
        "\n",
        "# Get training data\n",
        "\n",
        "train_data_by_user = []\n",
        "for user in train_data['cc_num'].unique():\n",
        "  if train_data[train_data['cc_num'] == user].shape[0] > 1:\n",
        "    user_data = train_data[train_data['cc_num'] == user].drop(['cc_num', 'is_fraud'], axis=1)\n",
        "    user_data = np.append(user_data, np.zeros((max_len - user_data.shape[0], user_data.shape[1])), axis=0)\n",
        "    train_data_by_user.append(torch.from_numpy(user_data))\n",
        "train_data_by_user_tensor = torch.stack([user for user in train_data_by_user])\n",
        "\n",
        "train_tgt_data = train_data_by_user_tensor\n",
        "\n",
        "# Get testing data\n",
        "\n",
        "test_data_by_user = []\n",
        "for user in test_data['cc_num'].unique():\n",
        "  if test_data[test_data['cc_num'] == user].shape[0] > 1:\n",
        "    test_user_data = test_data[test_data['cc_num'] == user].drop(['cc_num', 'is_fraud'], axis=1)\n",
        "    test_user_data = np.append(test_user_data, np.zeros((max_len - test_user_data.shape[0], test_user_data.shape[1])), axis=0)\n",
        "    test_data_by_user.append(torch.from_numpy(test_user_data))\n",
        "test_data_by_user_tensor = torch.stack([user for user in test_data_by_user])\n",
        "\n",
        "test_tgt_data = test_data_by_user_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSOrqFMsb00h",
        "outputId": "5464d6be-0791-45e3-bf74-1cc7fe9297b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([13, 2049, 11])\n",
            "torch.Size([25, 2049, 11])\n"
          ]
        }
      ],
      "source": [
        "print(train_tgt_data.shape)\n",
        "print(test_tgt_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning\n",
        "import optuna\n",
        "\n",
        "# Define objective, then define trial where parameters can vary, then study.optimize\n",
        "\n",
        "def get_best_params(train_data):\n",
        "  trial_data = []\n",
        "\n",
        "  def objective(trial):\n",
        "    # Define parameters to optimize\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 1e-6, 1e-4, log=True),\n",
        "        'd_model': trial.suggest_int('d_model', 16, 128),\n",
        "        'dropout': trial.suggest_float('dropout', 0.1, 0.5),\n",
        "        'num_layers': trial.suggest_int('num_layers', 1, 10),\n",
        "    }\n",
        "\n",
        "    # Train model\n",
        "    np.random.seed(42)\n",
        "\n",
        "    transformer = Transformer(categorical, numerical, params['num_layers'], max_len+1, params['d_model'] * 4, 1, 4, 128, params['dropout']) # parameters in the custom format for my transformer class\n",
        "    criterion_cat = nn.CrossEntropyLoss()\n",
        "    criterion_num = nn.MSELoss()\n",
        "    optimizer = optim.Adam(transformer.parameters(), lr=params['learning_rate'])\n",
        "\n",
        "    transformer.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    for user in range(len(train_data) // 3):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      train_input = train_tgt_data[user, :-1, :]  # (seq_len - 1, num_features)\n",
        "\n",
        "      train_target = train_tgt_data[user, 1:, :]  # (seq_len - 1, num_features)\n",
        "\n",
        "      _, preds_cat, preds_num = transformer(train_input)\n",
        "\n",
        "      train_tgt_cat = train_target[:, :len(categorical)].long()  # (seq_len - 1, num_categorical)\n",
        "      train_tgt_num = train_target[:, len(categorical):len(categorical) + numerical].float()  # (seq_len - 1, num_numeric)\n",
        "\n",
        "      # Loss calculations\n",
        "      cat_loss = sum(\n",
        "          criterion_cat(pred.squeeze(0)[: train_num_trans_per_user[user]-1], train_tgt_cat[:, i][1: train_num_trans_per_user[user]].to(pred.device))\n",
        "          for i, pred in enumerate(preds_cat)\n",
        "      ) / len(preds_cat)\n",
        "\n",
        "      num_loss = sum(\n",
        "          criterion_num(pred.squeeze(0).squeeze(1)[: train_num_trans_per_user[user]-1], train_tgt_num[:, i][1: train_num_trans_per_user[user]])\n",
        "          for i, pred in enumerate(preds_num)\n",
        "      ) / len(preds_num)\n",
        "\n",
        "      loss = cat_loss * 0.85 + num_loss * 0.15\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss += loss.item()\n",
        "    return total_loss / len(train_data)\n",
        "\n",
        "  study = optuna.create_study(direction='minimize')\n",
        "  study.optimize(objective, n_trials=25, show_progress_bar=True)\n",
        "\n",
        "  return study.best_params\n"
      ],
      "metadata": {
        "id": "2X8QHBkBjPai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical = (15, 13, 32, 25, 61, 61, 8) # (category, Month, Day, Hour, Minute, Second, dayOfWeek)\n",
        "numerical = 4 # (amt, merch_lat, merch_long, LatLong_Dist, hour_amt, category_amt)\n",
        "num_layers = 6\n",
        "\n",
        "# best_params = get_best_params(train_data_by_user)\n",
        "# print(best_params)"
      ],
      "metadata": {
        "id": "WJhjonhkarGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eSGAq9Onn8x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "b03c246f-f8e1-425a-bea7-16645a8d9781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss 3.648399994923518 Cat loss 3.2243824005126953 Num loss 6.051165713713719\n",
            "Epoch 2 Loss 2.9065332412719727 Cat loss 3.173713152225201 Num loss 1.3925133897708013\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-16-1882552913.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtrain_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_tgt_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# (seq_len - 1, num_features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtrain_tgt_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (seq_len - 1, num_categorical)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-11-1346815602.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdec_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_embedded\u001b[0m \u001b[0;31m# (batch_size, seq_length, num_features * d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdec_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m       \u001b[0mdec_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# Use last transaction's output to predict the next one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-10-2521672027.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, tgt_mask)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mff_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-7-1298939847.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Q, K, V, mask)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_o\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, seq_length, d_model*num_features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-7-1298939847.py\u001b[0m in \u001b[0;36mscaled_dot_product_attention\u001b[0;34m(self, Q, K, V, mask)\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mscaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Calculate attention scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mattn_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, num_heads, seq_length, seq_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mattn_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1e9\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, num_heads, seq_length, seq_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import statistics\n",
        "\n",
        "# Define transformer model\n",
        "\n",
        "best_params = {'learning_rate': 1.3446273553256569e-06, 'd_model': 53, 'dropout': 0.3101802514701506, 'num_layers': 8}\n",
        "\n",
        "# transformer = Transformer(categorical, numerical, num_layers, max_len+1)\n",
        "\n",
        "transformer = Transformer(categorical, numerical, best_params['num_layers'], max_len+1, best_params['d_model'] * 4, 1, 4, 128, best_params['dropout']) # parameters in the custom format for my transformer class\n",
        "\n",
        "\n",
        "criterion_cat = nn.CrossEntropyLoss()\n",
        "criterion_num = nn.MSELoss()\n",
        "optimizer = optim.Adam(transformer.parameters(), lr=0.0001)\n",
        "\n",
        "transformer.train()\n",
        "\n",
        "train_preds_cat = []\n",
        "train_preds_num = []\n",
        "\n",
        "for epoch in range(75):\n",
        "  loss_avg, cat_loss_avg, num_loss_avg = 0, 0, 0\n",
        "  for user in range(len(train_data_by_user)):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    train_input = train_tgt_data[user, :-1, :]  # (seq_len - 1, num_features)\n",
        "\n",
        "    train_target = train_tgt_data[user, 1:, :]  # (seq_len - 1, num_features)\n",
        "\n",
        "    _, preds_cat, preds_num = transformer(train_input)\n",
        "\n",
        "    train_tgt_cat = train_target[:, :len(categorical)].long()  # (seq_len - 1, num_categorical)\n",
        "    train_tgt_num = train_target[:, len(categorical):len(categorical) + numerical].float()  # (seq_len - 1, num_numeric)\n",
        "\n",
        "    # Loss calculations\n",
        "    cat_loss = sum(\n",
        "        criterion_cat(pred.squeeze(0)[: train_num_trans_per_user[user]-1], train_tgt_cat[:, i][1: train_num_trans_per_user[user]].to(pred.device))\n",
        "        for i, pred in enumerate(preds_cat)\n",
        "    ) / len(preds_cat)\n",
        "\n",
        "    num_loss = sum(\n",
        "        criterion_num(pred.squeeze(0).squeeze(1)[: train_num_trans_per_user[user]-1], train_tgt_num[:, i][1: train_num_trans_per_user[user]])\n",
        "        for i, pred in enumerate(preds_num)\n",
        "    ) / len(preds_num)\n",
        "\n",
        "    loss = cat_loss * 0.85 + num_loss * 0.15\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss_avg += loss.item()\n",
        "    cat_loss_avg += cat_loss.item()\n",
        "    num_loss_avg += num_loss.item()\n",
        "  print('Epoch', epoch+1, 'Loss', loss_avg / len(train_data_by_user), 'Cat loss', cat_loss_avg / len(train_data_by_user), 'Num loss', num_loss_avg / len(train_data_by_user))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3h9r0gyboWNm"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Get true values\n",
        "train_tgt_cat = train_tgt_data[-1, :, :][:, :7].long()\n",
        "train_tgt_num = train_tgt_data[-1, :, :][:, 7:12].float()\n",
        "\n",
        "all_cat_preds, all_cat_labels = [[] for _ in categorical], [[] for _ in categorical]\n",
        "all_num_preds, all_num_labels = [[] for _ in range(5)], [[] for _ in range(4)]\n",
        "\n",
        "# Categorical predictions\n",
        "for i, pred in enumerate(preds_cat):\n",
        "  pred_labels = F.softmax(pred.squeeze(0), dim=1).argmax(dim=1).cpu().tolist()\n",
        "  true_labels = train_tgt_cat[:, i].cpu().tolist()\n",
        "  all_cat_preds[i].extend(pred_labels)\n",
        "  all_cat_labels[i].extend(true_labels)\n",
        "\n",
        "# Numeric predictions\n",
        "for i, pred in enumerate(preds_num):\n",
        "  all_num_preds[i].extend(pred.squeeze(0).squeeze(1).cpu().tolist())\n",
        "  all_num_labels[i].extend(train_tgt_num[:, i].cpu().tolist())\n",
        "\n",
        "cat_accuracies = [accuracy_score(true[:-1][1: train_num_trans_per_user[-1]], pred[:-1][: train_num_trans_per_user[-1]-1]) for true, pred in zip(all_cat_labels, all_cat_preds)]\n",
        "\n",
        "num_rmse = [mean_squared_error(true[:-1][1: train_num_trans_per_user[-1]], pred[:-1][: train_num_trans_per_user[-1]-1]) for true, pred in zip(all_num_labels, all_num_preds)]\n",
        "\n",
        "categories = ['Category', 'Month', 'Day', 'Hour', 'Minute', 'Second', 'dayOfWeek']\n",
        "for i in range(7):\n",
        "  print(categories[i], 'accuracy:', str(cat_accuracies[i] * 100) + '%')\n",
        "\n",
        "nums = ['Amount', 'Merch Lat', 'Merch Long', 'LatLong_Dist']\n",
        "for i in range(4):\n",
        "  print(nums[i], 'MSE:', str(num_rmse[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OF2UDwRxanYG"
      },
      "outputs": [],
      "source": [
        "import statistics\n",
        "print('Categorical predictions')\n",
        "for i, pred in enumerate(preds_cat):\n",
        "  print('PRED', F.softmax(pred.squeeze(0), dim=1)[: train_num_trans_per_user[-1]-1].argmax(dim=1).cpu().tolist())\n",
        "  print('TRUE', train_tgt_cat[:, i][1: train_num_trans_per_user[-1]].cpu().tolist())\n",
        "  print(\" \")\n",
        "print('Numerical predictions')\n",
        "for i, pred in enumerate(preds_num):\n",
        "  print('PRED', pred.squeeze(0)[: train_num_trans_per_user[-1]-1].squeeze(1).cpu().tolist())\n",
        "  print('TRUE', train_tgt_num[:, i][1: train_num_trans_per_user[-1]].cpu().tolist())\n",
        "  print(\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Model on Test Data"
      ],
      "metadata": {
        "id": "2MYIvWb4ugs1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKS_DmYhD7dS"
      },
      "outputs": [],
      "source": [
        "test_preds_cat = [] # List of 25 lists of probabilities for each of the 7 categorical features (1, 2048, 15), (1, 2048, 13), etc for all the transactions of a single user\n",
        "test_preds_num = [] # List of 25 lists of predictions for each of the 4 numeric features (1, 2048, 1) for all the transactions of a single user\n",
        "transformer.eval()\n",
        "with torch.no_grad():\n",
        "  for user in range(len(test_tgt_data)):\n",
        "    pred_next_emb, preds_cat, preds_num = transformer(test_tgt_data[user, :-1, :])\n",
        "    test_preds_cat.append(preds_cat)\n",
        "    test_preds_num.append(preds_num)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "preds_cat_tensor = []\n",
        "for user in range(len(test_preds_cat)): # want to make a tensor with 15 columns and ~25 * 2048 rows for the categorical probabilities for all users\n",
        "  preds_for_user = test_preds_cat[user]\n",
        "  preds_for_user_concat = torch.cat([F.softmax(pred, dim=2).argmax(dim=2).cpu() for pred in preds_for_user], dim=0) # (2048 rows, 4 columns)\n",
        "  preds_for_user_concat = torch.transpose(preds_for_user_concat, 0, 1)[:test_num_trans_per_user[user], :]\n",
        "  preds_cat_tensor.append(preds_for_user_concat)\n",
        "\n",
        "preds_cat_tensor = torch.concat(preds_cat_tensor, dim=0)\n",
        "print(preds_cat_tensor.shape)"
      ],
      "metadata": {
        "id": "v8a3hDRwWkre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_num_tensor = []\n",
        "for user in range(len(test_preds_num)): # want to make a tensor with 4 columns and ~25 * 2048 rows for the numerical predictions for all users\n",
        "  preds_for_user = test_preds_num[user]\n",
        "  preds_for_user_concat = torch.cat([pred.squeeze(0)[:test_num_trans_per_user[user], :] for pred in preds_for_user], dim=1) # (2048 rows, 4 columns)\n",
        "  preds_num_tensor.append(preds_for_user_concat)\n",
        "\n",
        "preds_num_tensor = torch.concat(preds_num_tensor, dim=0)\n",
        "print(preds_num_tensor.shape)"
      ],
      "metadata": {
        "id": "6mGf2acPWnXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_tensor = torch.cat([preds_cat_tensor, preds_num_tensor], dim=1)\n",
        "print(preds_tensor.shape)"
      ],
      "metadata": {
        "id": "mf164449Wo5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_df = pd.DataFrame(preds_tensor.numpy(), columns=test_data.columns.drop(['cc_num', 'is_fraud']))\n",
        "\n",
        "preds_df['is_fraud'] = test_data.reset_index(drop=True)['is_fraud']\n",
        "preds_df['cc_num'] = test_data.reset_index(drop=True)['cc_num']"
      ],
      "metadata": {
        "id": "8aZUqTdAWk6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_df.head()"
      ],
      "metadata": {
        "id": "QzDfLw9nW9AG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(transformer.state_dict(), '/content/drive/MyDrive/transformer_model.pth')"
      ],
      "metadata": {
        "id": "rI8zNjV8bKAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.to_csv('/content/drive/MyDrive/test_data_transformer.csv', index=False)"
      ],
      "metadata": {
        "id": "lSEh_jWQThGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.to_csv('/content/drive/MyDrive/train_data_transformer.csv', index=False)"
      ],
      "metadata": {
        "id": "PKl_IhF4seIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_df.to_csv('/content/drive/MyDrive/preds_df_transformer.csv', index=False)"
      ],
      "metadata": {
        "id": "ewvB7Rt9WuFY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}